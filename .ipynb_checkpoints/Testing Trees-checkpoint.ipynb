{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import feature_eng_function as f_eng\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from PCA_function import pca_data100\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_train = pd.read_csv(\"data/train.csv\")\n",
    "forest_test = pd.read_csv(\"data/test.csv\")\n",
    "forest_base_train = pd.read_csv(\"data/train_eng.csv\")\n",
    "forest_base_test = pd.read_csv(\"data/test_eng.csv\")\n",
    "forest_100_train = pd.read_csv(\"data/train_100.csv\")\n",
    "forest_100_test = pd.read_csv(\"data/test_100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create arrays for each of the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = forest_train['Cover_Type']\n",
    "ID = forest_test['Id']\n",
    "\n",
    "X_train = forest_train[[col for col in forest_train.columns.tolist() if col not in ['Id','Cover_Type']]].values\n",
    "X_train_base = forest_base_train[[col for col in forest_base_train.columns.tolist() if col not in ['Id','Cover_Type']]].values\n",
    "X_train_100 = forest_100_train[[col for col in forest_100_train.columns.tolist() if col not in ['Id','Cover_Type']]].values\n",
    "\n",
    "X_test = forest_test[[col for col in forest_test.columns.tolist() if col not in ['Id','Cover_Type']]].values\n",
    "X_test_base = forest_base_test[[col for col in forest_base_test.columns.tolist() if col not in ['Id','Cover_Type']]].values\n",
    "X_test_100 = forest_100_test[[col for col in forest_100_test.columns.tolist() if col not in ['Id','Cover_Type']]].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Models\n",
    "optimized_100_cv5_GBM = pickle.load( open('pickles/optimized_100_cv5_GBM.p', 'rb') )\n",
    "optimized_100_cv10_GBM = pickle.load( open('pickles/optimized_100_cv10_GBM.p', 'rb') )\n",
    "optimized_100_default_GBM = pickle.load( open('pickles/optimized_100_default_GBM.p', 'rb') )\n",
    "optimized_base_cv5_GBM = pickle.load( open('pickles/optimized_base_cv5_GBM.p', 'rb') )\n",
    "optimized_base_cv10_GBM  = pickle.load( open('pickles/optimized_base_cv10_GBM.p', 'rb') )\n",
    "optimized_base_default_GBM  = pickle.load( open('pickles/optimized_base_default_GBM.p', 'rb') )\n",
    "optimized_kaggle_default_GBM = pickle.load( open('pickles/optimized_kaggle_default_GBM.p', 'rb') )\n",
    "optimized_kaggle_cv5_GBM = pickle.load( open('pickles/optimized_kaggle_cv5_GBM.p', 'rb') )\n",
    "optimized_kaggle_cv10_GBM = pickle.load( open('pickles/optimized_kaggle_cv10_GBM.p', 'rb') )\n",
    "\n",
    "# Random Forest Models\n",
    "optimized_100_cv5_RF = pickle.load( open('pickles/optimized_100_cv5_RF.p', 'rb') )\n",
    "#optimized_100_cv10_RF = pickle.load( open('pickles/optimized_100_cv10_RF.p', 'rb') )\n",
    "optimized_base_cv5_RF = pickle.load( open('pickles/optimized_base_cv5_RF.p', 'rb') )\n",
    "optimized_base_cv10_RF = pickle.load( open('pickles/optimized_base_cv10_RF.p', 'rb') )\n",
    "optimized_kaggle_cv5_RF = pickle.load( open('pickles/optimized_kaggle_cv5_RF.p', 'rb') )\n",
    "optimized_kaggle_cv10_RF = pickle.load( open('pickles/optimized_kaggle_cv10_RF.p', 'rb') )\n",
    "\n",
    "#Extra Trees Models\n",
    "#optimized_kaggle_cv10_ET = pickle.load( open('pickles/optimized_kaggle_cv10_ET.p', 'rb') )\n",
    "#optimized_base_cv10_ET = pickle.load( open('pickles/optimized_base_cv10_ET.p', 'rb') )\n",
    "#optimized_100_cv10_ET = pickle.load( open('pickles/optimized_100_cv10_ET.p', 'rb') )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lists of models to test on for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_100 = [\n",
    "    ('optimized_100_cv5_GBM',optimized_100_cv5_GBM),\n",
    "    ('optimized_100_cv10_GBM',optimized_100_cv10_GBM),\n",
    "    ('optimized_100_default_GBM',optimized_100_default_GBM),\n",
    "    ('optimized_100_cv5_RF',optimized_100_cv5_RF)#,\n",
    "    #('optimized_100_cv10_RF',optimized_100_cv10_RF)#,\n",
    "    #('optimized_kaggle_cv10_ET',optimized_kaggle_cv10_ET)\n",
    "]\n",
    "\n",
    "models_base = [\n",
    "    ('optimized_base_cv5_GBM',optimized_base_cv5_GBM),\n",
    "    ('optimized_base_cv10_GBM',optimized_base_cv10_GBM),\n",
    "    ('optimized_base_default_GBM',optimized_base_default_GBM),\n",
    "    ('optimized_base_cv5_RF',optimized_base_cv5_RF),\n",
    "    ('optimized_base_cv10_RF',optimized_base_cv10_RF)#,\n",
    "    #('optimized_base_cv10_ET',optimized_base_cv10_ET)\n",
    "]\n",
    "\n",
    "models_kaggle = [\n",
    "    ('optimized_kaggle_cv5_GBM',optimized_kaggle_cv5_GBM),\n",
    "    ('optimized_kaggle_cv10_GBM',optimized_kaggle_cv10_GBM),\n",
    "    ('optimized_kaggle_default_GBM',optimized_kaggle_default_GBM),\n",
    "    ('optimized_kaggle_cv5_RF',optimized_kaggle_cv5_RF),\n",
    "    ('optimized_kaggle_cv10_RF',optimized_kaggle_cv10_RF)#,\n",
    "    #('optimized_kaggle_cv10_ET',optimized_kaggle_cv10_ET) \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test each of the models and import into data frame to view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(models_kaggle)):\n",
    "    m = models_kaggle[i][0]\n",
    "    mod = models_kaggle[i][1]\n",
    "    \n",
    "    results = pd.DataFrame(ID)\n",
    "    results['Cover_Type'] = mod.predict(X_test)\n",
    "    results['Cover_Type'] = results['Cover_Type'].astype(int)\n",
    "    \n",
    "    filename = str('submissions/' + m + '.csv')\n",
    "    results.to_csv(filename, index=False)\n",
    "    \n",
    "for i in range(len(models_base)):\n",
    "    m = models_base[i][0]\n",
    "    mod = models_base[i][1]\n",
    "    \n",
    "    results = pd.DataFrame(ID)\n",
    "    results['Cover_Type'] = mod.predict(X_test_base)\n",
    "    results['Cover_Type'] = results['Cover_Type'].astype(int)\n",
    "    \n",
    "    filename = str('submissions/' + m + '.csv')\n",
    "    results.to_csv(filename, index=False)\n",
    "    \n",
    "for i in range(len(models_100)):\n",
    "    m = models_100[i][0]\n",
    "    mod = models_100[i][1]\n",
    "    \n",
    "    results = pd.DataFrame(ID)\n",
    "    results['Cover_Type'] = mod.predict(X_test_100)\n",
    "    results['Cover_Type'] = results['Cover_Type'].astype(int)\n",
    "    \n",
    "    filename = str('submissions/' + m + '.csv')\n",
    "    results.to_csv(filename, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
